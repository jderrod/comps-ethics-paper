\documentclass[10pt,twocolumn]{article}

% use the oxycomps style file
\usepackage{oxycomps}

% usage: \fixme[comments describing issue]{text to be fixed}
% define \fixme as not doing anything special
\newcommand{\fixme}[2][]{#2}
% overwrite it so it shows up as red
\renewcommand{\fixme}[2][]{\textcolor{red}{#2}}
% overwrite it again so related text shows as footnotes
%\renewcommand{\fixme}[2][]{\textcolor{red}{#2\footnote{#1}}}

% read references.bib for the bibtex data
\bibliography{references}

% include metadata in the generated pdf file
\pdfinfo{
    /Title (Autonomous Vehicle - Ethics Paper)
    /Author (James Derrod)
}

% set the title and author information
\title{Autonomous Vehicle - Ethics Paper}
\author{James Derrod}
\affiliation{Occidental College}
\email{jderrod@oxy.edu}

\begin{document}

\maketitle

\section{Introduction} In the rapidly evolving field of artificial intelligence, the integration of deep reinforcement learning (DRL) with autonomous systems presents both groundbreaking potential and a multitude of ethical challenges. 

For my comps project, I plan on developing a DRL algorithm to train an agent to successfully drive a car within a Unity environment. Unity is one of the largest, publicly available platforms for video game development, and allows for the use of the MLAgents toolkit, as well as rendering capabilities. The MLAgents toolkit is useful for integrating machine learning agents into Unity, facilitating the training, evaluation, and visualization of an agent's learning process and operational efficiency.

The problem of teaching an agent to drive a car using DRL in Unity can be framed as a Markov decision process (MDP), which is a mathematical framework for modeling decision making in situations where outcomes are partially random and partially under the control of a decision maker. Basic reinforcement learning is modeled as a Markov decision process, defined as:
\begin{itemize}
    \item a set of environment and agent states, \textbf{\textit{S}};
    \item a set of actions, \textbf{\textit{A}}, the agent can take;
    \item A transition function to describe the probability of transition (at time \textbf{\textit{t}}) from state \textbf{\textit{s}} to \textbf{\textit{s'}} under action \textbf{\textit{a}} \cite{MarkovDecisionProcess}.
\end{itemize}

In the context of my project, the components of the MDP are:
\begin{itemize}
    \item \textbf{States }(\textbf{\textit{S}}):
    \begin{itemize}
        \item A state represents the current condition of the environment as perceived by the vehicle/agent.
        \item This could include:
        \begin{itemize}
            \item Vehicle's position, orientation, speed, and acceleration.
            \item Road conditions, number of lanes, size of lanes, traffic lights
            \item Position and velocity of observed nearby vehicles and other dynamic obstacles.
            \item Positions of non-moving observed obstacles such as barriers, lights, or signs.
        \end{itemize}
    \end{itemize}
    \item \textbf{Actions }(\textbf{\textit{A}}):
    \begin{itemize}
        \item Actions are the set of possible moves the agent can take at any state. 
        \item This could include:
        \begin{itemize}
            \item Accelerating, decelerating, or maintaining current speed. Defined by value in range \newline[-1,1].
            \item Turning right, turning left, maintaining current direction. Defined by value in range \newline[-1,1].
        \end{itemize}
    \end{itemize}
    \item \textbf{Transition Function } (\textbf{\textit{P}}):
    \begin{itemize}
        \item This function will define the probability of moving from one state to another, given a particular action.
        \item \textbf{Ex.} If the agent decides to accelerate, this function will provide the probabilities of resultant states, such as:
        \begin{itemize}
            \item Successfully overtaking another vehicle
            \item An unwanted collision with an obstacle due to excessive speed.
        \end{itemize}
    \end{itemize}
\end{itemize}

Additionally, we want to define a reward function to shape the actions the agent will take given the goal of the agent. 

\begin{itemize}
    \item \textbf{Rewards }(\textbf{\textit{R}}):
    \begin{itemize}
        \item Rewards given for maintaining safe distance, staying within speed limits, obeying traffic rules, staying on road, moving towards goal.
        \item Negative rewards (penalties) given for collisions, near misses, lane/traffic violations.
    \end{itemize}
\end{itemize}

Finally, we need to define a discount factor ($\gamma$) which determines the present value of future rewards with a range of [0,1]. A higher discount factor would lead to an increased value for future rewards. A discount factor closer to 1 would encourage strategies that prioritize long-term benefits, such as maintaining a safe distance behind a vehicle to prevent a potential collision rather than prioritizing immediate gains like speeding to pass a slow vehicle.

With these elements defined, the problem of training an autonomous vehicle using DRL involves implementing a learning policy that maximizes cumulative future rewards.

This will be done through three steps:
\begin{enumerate}
    \item \textbf{Initialization}: Start with random guesses for the policy, mapping from states to chosen actions.
    \item \textbf{Experience Collection}: The agent will interact with the potentially dynamic environment, collecting and documenting experiences in terms of states, actions, rewards, and next states.
    \item \textbf{Learning}: Implementing an algorithm such as Deep Q-Networks (DQN) to update the policy based on experiences collected. These updates aim to gradually converge towards an optimal policy that maximizes the cumulative reward.
\end{enumerate}

My project aims to explore the capabilities of DRL within a controlled simulation, and push the boundaries of what autonomous systems can learn and achieve. However, the introduction of such sophisticated systems into widespread use brings with it a plethora of ethical considerations that must be thoroughly examined. This paper will address these issues, which include but are not limited to:
\begin{itemize}
    \item Data bias
    \item Accessibility
    \item Power distribution
    \item Potential for misuse
\end{itemize}

I argue that completely addressing all ethical concerns associated with this technology is unattainable due to inherent limitations and complexities in the current technological landscape. By exploring each ethical concern in detail, this paper aims to  highlight the significant challenges that and inevitable shortcomings of ethical management of deploying reinforcement learning in autonomous navigation systems.
\section{Data Bias}
    Data bias occurs when an algorithm produces systematic errors due to inaccuracies in the data input. In machine learning, this often arises from non-representative or incomplete training data.

    In autonomous driving systems, bias can lead to decisions that are not only incorrect, but potentially dangerous\cite{AlgorithmBiasInAutonomousSystems}.
\subsection{Sources of Data Bias in this Project}
    \begin{itemize}
        \item \textbf{Simulated Environment Bias}: A simulated scenario will not fully account for the diversity of real world driving conditions.
        \item \textbf{Sampling Bias}: Selection of specific scenarios might disproportionately represent certain situations. A simulation will not accurately represent the variability in pedestrian behavior, complexities of different traffic patterns, or levels of visibility.
        \item \textbf{Human Input Bias}: "Safe Driving" may have a different definition for whoever is developing the rewards/algorithm, influenced by their own driving experience.
    \end{itemize}
\subsection{Impacts of Data Bias}
    \begin{itemize}
        \item \textbf{Performance Limitations}: A model trained in biased conditions may excel in simulated tests but perform poorly in real world applications. This is often due to the model encountering situations it has not encountered in training and therefor has not learned how to handle those situations.
        \item \textbf{Safety Concerns}: A model trained predominately in daytime conditions might fail to appropriately recognize pedestrians at night, leading to higher risk of accidents.
        \item \textbf{Social Implications}: Systemic bias may emerge if, for example, a model performed well in geographically typical scenarios of the developed world, but poorly in less developed scenarios.
    \end{itemize}
\subsection{Challenges of Mitigating Data Bias}
\begin{itemize}
    \item \textbf{Complexity of Real World Representation}: Practical limitations must be acknowledged in simulating every possible driving condition due to technological constraints and the increase in complexity it would entail.
    \item \textbf{Bias Identification and Correction}: Biases are often not recognized until specific failures occur, prompting a return to the development phase to integrate new scenarios or re-balance the dataset.
\end{itemize}

\section{Accessibility}
    Accessibility in autonomous vehicle technologies refers to the design of systems that are usable by people with a wide range of abilities and disabilities. In the context of deep learning and autonomous driving, ensuring accessibility is challenging and often overlooked in system design\cite{AccessibilityInAutonomousVehicles}.

\subsection{Sources of Accessibility Issues in this Project}
    \begin{itemize}
        \item \textbf{Interface Design}: The user interface of the autonomous system may not be designed to accommodate users with varying physical, cognitive, and sensory abilities.
        \item \textbf{Technological Exclusivity}: Advanced technologies often require interactions that may exclude non-technical users or those with certain disabilities.
        \item \textbf{Economic Barriers}: The high cost of development and implementation of accessible technologies can lead to prioritization decisions that exclude certain user groups.
    \end{itemize}

\subsection{Impacts of Poor Accessibility}
    \begin{itemize}
        \item \textbf{User Exclusion}: If the system is not accessible, it may exclude people with disabilities from utilizing autonomous vehicles, potentially increasing societal inequalities.
        \item \textbf{Safety Risks}: Inaccessible emergency interfaces or controls can pose higher safety risks to users with disabilities.
    \end{itemize}

\subsection{Challenges of Enhancing Accessibility}
    \begin{itemize}
        \item \textbf{Design Complexity}: Creating universally accessible systems increases the complexity of the design and testing phases.
        \item \textbf{Cost Implications}: The financial burden of implementing comprehensive accessibility features can be significant.
        \item \textbf{Continuous Adaptation}: Accessibility needs change as technologies and societal norms evolve, requiring ongoing updates and refinements.
    \end{itemize}


\section{Power Distribution}
    Power distribution in the context of autonomous vehicle technology refers to how decision-making capabilities and operational control are allocated among different stakeholders, including developers, users, regulatory bodies, and potentially malicious actors. The centralization or decentralization of power raises significant ethical concerns, particularly regarding autonomy, surveillance, and control \cite{AVPowerInequity}.

\subsection{Sources of Power Imbalance in this Project}
    \begin{itemize}
        \item \textbf{Developer Control}: Developers and corporations often retain significant control over autonomous technology, including proprietary software and hardware, data collection, and algorithm updates. This centralization of control can limit users' autonomy and potentially lead to dependencies that are difficult to break.
        \item \textbf{User Autonomy}: While autonomous vehicles promise enhanced mobility, they also risk diminishing the user's active decision-making role. Dependence on automated systems may erode individuals' skills and decision-making capacities, potentially leading to a passivity that can be exploited.
        \item \textbf{Regulatory Influence}: Governments and regulatory bodies possess the power to dictate terms of technology deployment, privacy standards, and safety regulations. However, their influence is often reactive and lagging behind technological advances, which may prevent timely and effective governance.
    \end{itemize}

\subsection{Impacts of Power Distribution}
    \begin{itemize}
        \item \textbf{Surveillance and Privacy}: Centralized control over autonomous vehicles could facilitate unprecedented levels of surveillance by developers or governments, especially as these vehicles are equipped to collect extensive data about users and their environments.
        \item \textbf{Manipulation and Control}: The concentration of power with developers or regulatory bodies could lead to scenarios where vehicle behavior is remotely manipulated for commercial or law enforcement purposes, raising acute ethical and privacy concerns.
        \item \textbf{Market Dominance}: The ability of large corporations to dominate the market with advanced technologies can stifle competition and innovation, potentially leading to monopolistic behaviors and further concentrating power.
    \end{itemize}

\subsection{Challenges of Addressing Power Imbalance}
    \begin{itemize}
        \item \textbf{Technological Opaqueness}: The complexity and proprietary nature of autonomous vehicle technologies make it difficult for users and regulators to fully understand and effectively oversee these systems. This opaqueness can shield significant power imbalances from public scrutiny and regulatory oversight.
        \item \textbf{Evolving Technologies}: Rapid advancements in technology continually shift power dynamics, often outpacing the development of corresponding ethical norms and regulatory frameworks. This lag complicates efforts to establish fair and equitable power distributions.
        \item \textbf{Global Disparities}: Different countries and regions may have varying capabilities to adopt and regulate new technologies, leading to global disparities in power and control over autonomous vehicle technology. This can exacerbate inequalities and hinder comprehensive governance.
    \end{itemize}

\section{Potential for Misuse}
    The development of autonomous vehicles using deep reinforcement learning opens up several avenues for misuse that can have significant societal impacts. Whether by malicious actors or through unintended consequences, the potential for misuse is a critical ethical concern that complicates the deployment of this technology\cite{AVCyberAttacks}.

\subsection{Sources of Potential Misuse}
    \begin{itemize}
        \item \textbf{Malicious Exploits}: As autonomous vehicles are controlled by software that interacts with a complex environment, they are vulnerable to hacking and other cyber attacks. These exploits could lead to unauthorized control over vehicle behavior, endangering public safety.
        \item \textbf{Surveillance Abuse}: Given the data-intensive nature of autonomous driving technologies, there is a risk that this data could be used for intrusive surveillance. This could be perpetrated not just by state actors but also private companies or criminals, using data to track individuals without their consent.
        \item \textbf{Software Manipulation}: The software that governs autonomous vehicles can be altered to behave in unethical ways, such as prioritizing the safety of the vehicle over pedestrians in violation of ethical norms, or creating situations that could lead to insurance fraud.
    \end{itemize}

\subsection{Impacts of Misuse}
    \begin{itemize}
        \item \textbf{Public Safety Risks}: Malicious control or failure modes introduced by exploits could result in accidents, injuries, or worse. The potential for widespread harm is significantly elevated with the proliferation of autonomous vehicles.
        \item \textbf{Privacy Violations}: Unauthorized surveillance and data misuse could lead to massive breaches of privacy, affecting countless individuals. These breaches would not only violate individual rights but could also undermine public trust in autonomous technologies.
        \item \textbf{Legal and Ethical Challenges}: Misuse of autonomous vehicle technology raises complex legal issues, such as liability in the case of accidents caused by manipulated software, and ethical issues regarding surveillance and data privacy.
    \end{itemize}

\subsection{Challenges of Mitigating Misuse}
    \begin{itemize}
        \item \textbf{Security Measures}: Implementing robust security measures to protect against hacking and unauthorized access remains a major technical challenge. The complexity of autonomous systems makes them difficult to secure completely.
        \item \textbf{Regulatory Oversight}: There is a need for comprehensive regulatory frameworks that can keep pace with technological advancements and address the many ways in which misuse can occur. Developing these frameworks is complicated by the global nature of technology deployment and the varying capabilities of regulatory bodies.
        \item \textbf{Technological Sophistication}: As autonomous technologies become more sophisticated, so too do the methods of misuse. Keeping ahead of malicious actors requires continuous innovation and vigilance in technology design and policy enforcement.
    \end{itemize}


\section{Conclusion}

This project applies deep reinforcement learning (DRL) to develop autonomous vehicles within a Unity environment, bringing to light several ethical challenges. These include data bias, accessibility limitations, power distribution issues, and the potential for misuse. These problems highlight the inherent limitations of using simulated environments and centralized control systems in this technological field.

Despite the advancements demonstrated, the reasons presented argue that it is not possible to fully address all ethical concerns with the current technology, both within this project as well as the field of autonomous vehicles as a whole. The fast pace at which technology evolves makes it even harder to manage these issues effectively.

This highlights the importance of continuous ethical review and the need to adapt our methods as technology changes, and stresses the need for ongoing improvements to ensure that technological developments are in line with ethical standards.

\printbibliography

\end{document}


